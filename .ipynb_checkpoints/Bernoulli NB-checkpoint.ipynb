{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#训练数据\n",
    "X=['Chinese Beijing Chinese', 'Chinese Chinese Shanghai', 'Chinese Macao',  'Tokyo Japan Chinese']\n",
    "y = ['yes','yes','yes','no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#以词频为特征向量化\n",
    "cv = CountVectorizer().fit(X)\n",
    "X =cv.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词典： [('beijing', 0), ('chinese', 1), ('japan', 2), ('macao', 3), ('shanghai', 4), ('tokyo', 5)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 0, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('词典：',sorted(cv.vocabulary_.items(), key=lambda d: d[1]))\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.,  3.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  1.,  0.,  0.,  1.],\n",
       "       [ 1.,  3.,  0.,  1.,  1.,  0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.25,  0.75])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-0.28768207])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.80893321,  0.19106679]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BernoulliNB()\n",
    "clf.fit(X,y)\n",
    "clf.class_count_ #类计数\n",
    "clf.feature_count_  #特征计数\n",
    "np.e ** clf.class_log_prior_ #类权重 log\n",
    "clf.intercept_\n",
    "\n",
    "#预测\n",
    "x_val = cv.transform(['Chinese Chinese Chinese Tokyo Japan']) #训练样本，向量化\n",
    "x_val.toarray()[0]  #\n",
    "clf.predict_proba(x_val) #模型预测概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2伯努利模型\n",
    "\n",
    "1）基本原理\n",
    "\n",
    "P(c)= 类c下文件总数/整个训练样本的文件总数\n",
    "\n",
    "P(tk|c)=(类c下包含单词tk的文件数+1)/(类c下文件总数+2)\n",
    "\n",
    ">平滑稀疏等于1时，相当于对每个分类，增加一个全0的记录 和一个全1的记录， 这样每个特征的计数加1，每个分类的计数加2\n",
    "\n",
    "2）举例\n",
    "\n",
    "使用前面例子中的数据，模型换成伯努利模型。\n",
    "\n",
    "类yes下总共有3个文件，类no下有1个文件，训练样本文件总数为11，因此P(yes)=3/4, P(Chinese | yes)=(3+1)/(3+2)=4/5，条件概率如下：\n",
    "\n",
    "P(Japan | yes)=P(Tokyo | yes)=(0+1)/(3+2)=1/5\n",
    "\n",
    "P(Beijing | yes)= P(Macao|yes)= P(Shanghai |yes)=(1+1)/(3+2)=2/5\n",
    "\n",
    "P(Chinese|no)=(1+1)/(1+2)=2/3\n",
    "\n",
    "P(Japan|no)=P(Tokyo| no) =(1+1)/(1+2)=2/3\n",
    "\n",
    "P(Beijing| no)= P(Macao| no)= P(Shanghai | no)=(0+1)/(1+2)=1/3\n",
    "\n",
    "有了以上类条件概率，开始计算后验概率，\n",
    "\n",
    "P(yes|d)=P(yes)×P(Chinese|yes)×P(Japan|yes)×P(Tokyo|yes)×(1-P(Beijing|yes))×(1-P(Shanghai|yes))×(1-P(Macao|yes))=3/4×4/5×1/5×1/5×(1-2/5) ×(1-2/5)×(1-2/5)=81/15625≈0.005\n",
    "\n",
    "P(no|d)= 1/4×2/3×2/3×2/3×(1-1/3)×(1-1/3)×(1-1/3)=16/729≈0.022\n",
    "\n",
    "因此，这个文档不属于类别china。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 原始数据\n",
    "\n",
    "| beijing | chinese | japan | macao | shanghai | tokyo | y|\n",
    "|---------|---------|-------|-------|--------- |-------|--|\n",
    "|1|2|0|0|0|0|1|\n",
    "|0|2|0|0|1|0|1|\n",
    "|0|1|0|1|0|0|1|\n",
    "|0|1|1|0|0|1|0|\n",
    "\n",
    "#### binary\n",
    "\n",
    "| beijing | chinese | japan | macao | shanghai | tokyo | y|\n",
    "|---------|---------|-------|-------|--------- |-------| -|\n",
    "|1|1|0|0|0|0|1|\n",
    "|0|1|0|0|1|0|1|\n",
    "|0|1|0|1|0|0|1|\n",
    "|0|1|1|0|0|1|0|\n",
    "\n",
    "#### features count\n",
    "| beijing | chinese | japan | macao | shanghai | tokyo | y|\n",
    "|---------|---------|-------|-------|--------- |-------| -|\n",
    "|0|1|1|0|0|1|0|\n",
    "|1|3|0|1|1|0|1|\n",
    "\n",
    "#### class count\n",
    "|class0| class1|\n",
    "|-|-|\n",
    "|1|3|\n",
    "\n",
    "#### Laplace smoothing parameter  : alpha = 1\n",
    "\n",
    "#### prob\n",
    "* P('beijing'|y=0) = P('shanghai'|y=0) = P('macao'|y=0) = (0 + 1) / (1+2) = 1/3\n",
    "* P('chinese'|y=0) = P('japan'|y=0)= P('tokyo'|y=0) = (1 + 1) / (1+2) = 2/3\n",
    "\n",
    "* P('beijing'|y=1) = P('shanghai'|y=1) = P('macao'|y=1) = (1 + 1) / (3+2) = 2/5\n",
    "* P('chinese'|y=1)  = (3 + 1) / (3+2) = 4/5\n",
    "* P('japan'|y=1)  = P('tokyo'|y=1) = (0 + 1) / (3+2) = 1/5\n",
    "\n",
    "* P(y=0) = 1/4\n",
    "* P(y=1) = 3/4\n",
    "\n",
    "\n",
    "#### predict\n",
    "> Chinese Chinese Chinese Tokyo Japan\n",
    "\n",
    "x = [0, 1, 1, 0, 0, 1]\n",
    "\n",
    "\n",
    "`\n",
    "p(y=0|x) = (1-1/3) * 2/3 * 2/3 * (1-1/3) *  (1-1/3) * (2/3) * 1/4 = 0.02194 = 0.80887\n",
    "p(y=1|x) = (1-2/5) * 4/5 * 1/5 * (1-2/5) *  (1-2/5) * (1/5) * 3/4 = 0.005184 = 0.1911\n",
    "`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
