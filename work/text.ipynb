{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba as jb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer \n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root = 'd:/tempdata/'\n",
    "file_name = '163_news_data2018_01_08_08_00_00.csv'\n",
    "file = root + file_name\n",
    "df = pd.DataFrame.from_csv(file,encoding='gbk', index_col=None)\n",
    "df = df[['一级目录','二级目录','标题','内容']]\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4393 entries, 0 to 4604\n",
      "Data columns (total 4 columns):\n",
      "一级目录    4393 non-null object\n",
      "二级目录    4393 non-null object\n",
      "标题      4393 non-null object\n",
      "内容      4393 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 171.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#df.head()\n",
    "#df.loc(291)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>标题</th>\n",
       "      <th>内容</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>一级目录</th>\n",
       "      <th>二级目录</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">体育</th>\n",
       "      <th>CBA</th>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NBA</th>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>中国足球</th>\n",
       "      <td>295</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>国际足球</th>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">娱乐</th>\n",
       "      <th>明星</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>电影</th>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>电视</th>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>综艺</th>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>音乐</th>\n",
       "      <td>139</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">时事新闻</th>\n",
       "      <th>国内</th>\n",
       "      <td>557</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>国际</th>\n",
       "      <td>557</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>社会</th>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">科技</th>\n",
       "      <th>互联网</th>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>数码</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>科学</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">财经</th>\n",
       "      <th>宏观经济</th>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>理财</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>股票</th>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            标题   内容\n",
       "一级目录 二级目录          \n",
       "体育   CBA   293  293\n",
       "     NBA   244  244\n",
       "     中国足球  295  295\n",
       "     国际足球  289  289\n",
       "娱乐   明星     33   33\n",
       "     电影    248  248\n",
       "     电视    290  290\n",
       "     综艺    114  114\n",
       "     音乐    139  139\n",
       "时事新闻 国内    557  557\n",
       "     国际    557  557\n",
       "     社会    554  554\n",
       "科技   互联网   126  126\n",
       "     数码     30   30\n",
       "     科学    100  100\n",
       "财经   宏观经济  102  102\n",
       "     理财     17   17\n",
       "     股票    405  405"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['一级目录','二级目录']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1, y2, title, content = [df.一级目录, df.二级目录, df.标题, df.内容]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#加载停用词\n",
    "f_stop_words = open(root + 'stop_words.txt', encoding='utf-8')\n",
    "stop_words = f_stop_words.readline().split('\\t')\n",
    "f_stop_words.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\GANGZ\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 2.282 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "title_cuted = [' '.join(jb.cut(x)) for x in title.values ]\n",
    "content_cuted = [' '.join(jb.cut(x)) for x in content.values ]\n",
    "\n",
    "#tfidf title\n",
    "X1 = TfidfVectorizer(stop_words=stop_words).fit_transform(title_cuted)\n",
    "#count title\n",
    "X2 = CountVectorizer(stop_words=stop_words).fit_transform(title_cuted)\n",
    "\n",
    "#tiidf content\n",
    "X3 = TfidfVectorizer(stop_words=stop_words).fit_transform(content_cuted)\n",
    "#count content\n",
    "X4 = CountVectorizer(stop_words=stop_words).fit_transform(content_cuted)\n",
    "\n",
    "#binary\n",
    "X5 = X4>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB, title, class one: [ 0.90938511  0.8961039   0.91544715  0.9233279   0.91353997]\n",
      "LogisticRegression, title, class one: [ 0.9012945   0.87012987  0.88292683  0.86949429  0.88091354]\n"
     ]
    }
   ],
   "source": [
    "#使用标题训练一级目录\n",
    "X_train, X_val, y_train, y_val = train_test_split(X2,y1,test_size=0.3,random_state=42)\n",
    "\n",
    "#\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "score = cross_val_score(cv=5, estimator=clf, X=X_train, y=y_train)\n",
    "print('MultinomialNB, title, y1:', score)\n",
    "\n",
    "#\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "score = cross_val_score(cv=5, estimator=clf, X=X_train, y=y_train)\n",
    "print('LogisticRegression, title, y1:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB, title, class one: [ 0.72873194  0.73344103  0.747557    0.73278689  0.73563218]\n",
      "LogisticRegression, title, class one: [ 0.70626003  0.73344103  0.73778502  0.7295082   0.74220033]\n"
     ]
    }
   ],
   "source": [
    "#使用标题训练二级目录\n",
    "X_train, X_val, y_train, y_val = train_test_split(X2,y2,test_size=0.3,random_state=42)\n",
    "\n",
    "#\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "score = cross_val_score(cv=5, estimator=clf, X=X_train, y=y_train)\n",
    "print('MultinomialNB, title, y2:', score)\n",
    "\n",
    "#\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "score = cross_val_score(cv=5, estimator=clf, X=X_train, y=y_train)\n",
    "print('LogisticRegression, title, y2:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB, title, class one: [ 0.92071197  0.93668831  0.93658537  0.93311582  0.94290375] 0.927921092564\n",
      "LogisticRegression, title, class one: [ 0.94012945  0.94805195  0.93495935  0.93474715  0.93474715] 0.933990895296\n"
     ]
    }
   ],
   "source": [
    "#使用内容训练一级目录\n",
    "X_train, X_val, y_train, y_val = train_test_split(X4,y1,test_size=0.3,random_state=42)\n",
    "\n",
    "#\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "cv_score = cross_val_score(cv=5, estimator=clf, X=X_train, y=y_train)\n",
    "pre_score = clf.score(X=X_val, y=y_val)\n",
    "print('MultinomialNB, content, y1:', cv_score, pre_score)\n",
    "\n",
    "#\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "cv_score = cross_val_score(cv=5, estimator=clf, X=X_train, y=y_train)\n",
    "pre_score = clf.score(X=X_val, y=y_val)\n",
    "print('LogisticRegression, content, y1:', cv_score, pre_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB, title, class one: [ 0.79133226  0.80775444  0.79967427  0.79508197  0.81116585] 0.808801213961\n",
      "LogisticRegression, title, class one: [ 0.82985554  0.84006462  0.83061889  0.8147541   0.81116585] 0.829286798179\n",
      "max_df=0.3,LogisticRegression, content, class one: [ 0.82664526  0.84491115  0.82899023  0.81639344  0.8226601 ] 0.825493171472\n"
     ]
    }
   ],
   "source": [
    "#使用内容训练二级目录\n",
    "X_train, X_val, y_train, y_val = train_test_split(X4,y2,test_size=0.3,random_state=42)\n",
    "\n",
    "#\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "cv_score = cross_val_score(cv=5, estimator=clf, X=X_train, y=y_train)\n",
    "pre_score = clf.score(X=X_val, y=y_val)\n",
    "print('MultinomialNB, content, y2:', cv_score, pre_score)\n",
    "\n",
    "#\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "cv_score = cross_val_score(cv=5, estimator=clf, X=X_train, y=y_train)\n",
    "pre_score = clf.score(X=X_val, y=y_val)\n",
    "print('LogisticRegression, content, y2:', cv_score, pre_score)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "LogisticRegression, content, class one: [ 0.82182986  0.84168013  0.82410423  0.81967213  0.81444992] 0.820940819423\n",
      "0.2\n",
      "LogisticRegression, content, class one: [ 0.81861958  0.84491115  0.82084691  0.81803279  0.81609195] 0.827010622155\n",
      "0.3\n",
      "LogisticRegression, content, class one: [ 0.82664526  0.84491115  0.82899023  0.81639344  0.8226601 ] 0.825493171472\n",
      "0.5\n",
      "LogisticRegression, content, class one: [ 0.82504013  0.84329564  0.8257329   0.81147541  0.81773399] 0.830804248862\n",
      "0.8\n",
      "LogisticRegression, content, class one: [ 0.83306581  0.83844911  0.82899023  0.81311475  0.81280788] 0.828528072838\n",
      "1.0\n",
      "LogisticRegression, content, class one: [ 0.82985554  0.84006462  0.83061889  0.8147541   0.81116585] 0.829286798179\n"
     ]
    }
   ],
   "source": [
    "#限制max_df 优化\n",
    "for max_df in [0.1,0.2,0.3,0.5,0.8,1.0]:\n",
    "#\n",
    "    print(max_df)\n",
    "    X4 = CountVectorizer(stop_words=stop_words, max_df=max_df).fit_transform(content_cuted)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X4,y2,test_size=0.3,random_state=42)\n",
    "\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    cv_score = cross_val_score(cv=5, estimator=clf, X=X_train, y=y_train)\n",
    "    pre_score = clf.score(X=X_val, y=y_val)\n",
    "    print('LogisticRegression, content, class one:', cv_score, pre_score)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB, title, class one: [ 0.92718447  0.91720779  0.91869919  0.92169657  0.92822186] 0.926403641882\n",
      "LogisticRegression, title, class one: [ 0.94983819  0.95292208  0.95934959  0.95106036  0.95921697] 0.959028831563\n"
     ]
    }
   ],
   "source": [
    "#使用内容训练一级目录  X5，binary\n",
    "X_train, X_val, y_train, y_val = train_test_split(X5,y1,test_size=0.3,random_state=42)\n",
    "\n",
    "#\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "cv_score = cross_val_score(cv=5, estimator=clf, X=X_train, y=y_train)\n",
    "pre_score = clf.score(X=X_val, y=y_val)\n",
    "print('MultinomialNB, title, class one:', cv_score, pre_score)\n",
    "\n",
    "#\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "cv_score = cross_val_score(cv=5, estimator=clf, X=X_train, y=y_train)\n",
    "pre_score = clf.score(X=X_val, y=y_val)\n",
    "print('LogisticRegression, title, class one:', cv_score, pre_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB, title, class one: [ 0.75441413  0.75282714  0.747557    0.75081967  0.75369458] 0.764795144158\n",
      "LogisticRegression, title, class one: [ 0.85393258  0.85137318  0.85504886  0.84590164  0.8456486 ] 0.852807283763\n"
     ]
    }
   ],
   "source": [
    "#使用内容训练二级目录 X5，binary\n",
    "X_train, X_val, y_train, y_val = train_test_split(X5,y2,test_size=0.3,random_state=42)\n",
    "\n",
    "#\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "cv_score = cross_val_score(cv=5, estimator=clf, X=X_train, y=y_train)\n",
    "pre_score = clf.score(X=X_val, y=y_val)\n",
    "print('MultinomialNB, title, class one:', cv_score, pre_score)\n",
    "\n",
    "#\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "cv_score = cross_val_score(cv=5, estimator=clf, X=X_train, y=y_train)\n",
    "pre_score = clf.score(X=X_val, y=y_val)\n",
    "print('LogisticRegression, title, class one:', cv_score, pre_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB, title, class one: [ 0.75441413  0.75282714  0.747557    0.75081967  0.75369458] 0.764795144158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression, title, class one: [ 0.84911717  0.84652666  0.86482085  0.83442623  0.85714286] 0.858877086495\n"
     ]
    }
   ],
   "source": [
    "#使用内容训练二级目录 X5，binary, multinomial\n",
    "X_train, X_val, y_train, y_val = train_test_split(X5,y2,test_size=0.3,random_state=42)\n",
    "\n",
    "\n",
    "clf = LogisticRegression(multi_class='multinomial',solver='lbfgs', C=10)\n",
    "clf.fit(X_train, y_train)\n",
    "cv_score = cross_val_score(cv=5, estimator=clf, X=X_train, y=y_train)\n",
    "pre_score = clf.score(X=X_val, y=y_val)\n",
    "print('LogisticRegression, title, class one:', cv_score, pre_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
